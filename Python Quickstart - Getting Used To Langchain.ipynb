{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Python Quickstart - Getting Used to Langchain & OpenAI"
      ],
      "metadata": {
        "id": "noSK-KcQOtrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-YjY63a9OyJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Code from Pinecone: https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/langchain/handbook/00-langchain-intro.ipynb#scrollTo=l7yubiSJhIfs"
      ],
      "metadata": {
        "id": "bDi6XGAtOY0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "B_gdaznxOrcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Langchain"
      ],
      "metadata": {
        "id": "0KhsNIJROzIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r-ryCeG_f_GC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fc820f-6abb-4d89-df5c-0c96e51dba14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.2/477.2 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l7yubiSJhIfs"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, LLMChain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "su0Z51d0Oouq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpdXG9YtzrLJ"
      },
      "source": [
        "# Install OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHo2YRHPDgHH",
        "outputId": "e5dcf467-fc8e-4d16-f2e7-6b8bcc066fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.3 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "deWmOJecfbBr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'PASTE_YOUR_OPENAI_API_KEY_HERE'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "3Av2FjeHOnxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set The OpenAI Model to text-davinci-003"
      ],
      "metadata": {
        "id": "srPgenbMO6S9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AWnaTCP0Ryg"
      },
      "source": [
        "Then we decide on which model we'd like to use, there are several options but we will go with `text-davinci-003`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZhQSDoYe0ly4"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "davinci = OpenAI(model_name='text-davinci-003')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "qWgvZ0P4Olte"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGL2zs3uEVj6"
      },
      "source": [
        "# Use a Simple Template to answer questions with langchain and openAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build prompt template for simple question-answering\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: \"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=davinci\n",
        ")\n",
        "\n",
        "question = \"Who is Quentin Tarantino?\"\n",
        "\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngIlkkWpN5X-",
        "outputId": "c4fb83db-817b-44a1-e35e-d60e1aa27527"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Quentin Tarantino is an American film director, producer, screenwriter, and actor. He is best known for his films such as Pulp Fiction (1994), Reservoir Dogs (1992), Kill Bill (2003-2004), Jackie Brown (1997), and The Hateful Eight (2015). His films are characterized by nonlinear storylines, ensemble casts, satirical subject matter, and an aestheticization of violence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "EgG3fIJQOkwj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL-buasOKpKs"
      },
      "source": [
        "The same works again for multiple questions using `generate`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMua1MWcKtSx",
        "outputId": "520cffb7-9984-4fb0-ddb5-6d6d007f6ed7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text=' The Green Bay Packers won the Super Bowl in the 2010 season.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' You are 193.04 centimeters tall.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' The 12th person to walk on the moon was Harrison Schmitt, who was part of the Apollo 17 mission.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' A blade of grass does not have any eyes.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 75, 'total_tokens': 129, 'completion_tokens': 54}, 'model_name': 'text-davinci-003'})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "qs = [\n",
        "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
        "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
        "    {'question': \"Who was the 12th person on the moon?\"},\n",
        "    {'question': \"How many eyes does a blade of grass have?\"}\n",
        "]\n",
        "llm_chain.generate(qs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXQhQbd9MslW"
      },
      "source": [
        "Note that the below format doesn't feed the questions in iteratively but instead all in one chunk."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "roJOAh5uOjNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2-es7SgFddS",
        "outputId": "0b1218c5-4836-41b3-b4bf-561ddd2e3585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. The Green Bay Packers.\n",
            "2. 193 centimeters.\n",
            "3. Harrison Schmitt.\n",
            "4. None.\n"
          ]
        }
      ],
      "source": [
        "qs = [\n",
        "    \"Which NFL team won the Super Bowl in the 2010 season?\",\n",
        "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\",\n",
        "    \"Who was the 12th person on the moon?\",\n",
        "    \"How many eyes does a blade of grass have?\"\n",
        "]\n",
        "print(llm_chain.run(qs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybMkI18xfbBr"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12 (main, Apr  5 2022, 01:52:34) \n[Clang 12.0.0 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}